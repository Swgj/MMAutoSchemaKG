import os
import time
import argparse
import logging
from configparser import ConfigParser
from openai import OpenAI
from dotenv import load_dotenv

# å¼•å…¥åŸé¡¹ç›®ç»„ä»¶
from atlas_rag.llm_generator import LLMGenerator
from atlas_rag.kg_construction.triple_config import ProcessingConfig

# å¼•å…¥æˆ‘ä»¬æ„å»ºçš„å¤šæ¨¡æ€æŠ½å–å™¨
from atlas_rag.multimodal.extraction import MultimodalKGExtractor

load_dotenv()
logger = logging.getLogger(__name__)


def main():
    # 1. å‚æ•°è§£æ
    parser = argparse.ArgumentParser(description="Run Multimodal KG Extraction")
    parser.add_argument("--data_dir", type=str, default="example_data/locomo_hard_data/", help="Directory containing the json data")
    parser.add_argument("--filename", type=str, default="locomo_hard_0", help="Filename without extension (e.g. locomo_hard_0)")
    parser.add_argument("--model", type=str, default="gemini-2.5-flash", help="Model name (must support vision)")
    parser.add_argument("--api_key", type=str, default=os.environ.get("GEMINI_API_KEY"), help="API Key")
    parser.add_argument("--base_url", type=str, default=os.environ.get("GEMINI_BASE_URL"), help="Custom API Base URL")
    args = parser.parse_args()

    # 2. åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    # è¿™ä¸€æ­¥éå¸¸å…³é”®ï¼Œç¡®ä¿æ‚¨çš„ Client æŒ‡å‘äº†æ­£ç¡®çš„æœåŠ¡å•†
    if not args.api_key:
        print("âš ï¸ Warning: No API Key provided. Please set OPENAI_API_KEY env var or pass --api_key")

    client = OpenAI(
        api_key=args.api_key,
        base_url=args.base_url
    )

    # 3. åˆå§‹åŒ– LLM ç”Ÿæˆå™¨
    # max_workers æ§åˆ¶å¹¶å‘æ•°ï¼Œå¤šæ¨¡æ€è¯·æ±‚è¾ƒå¤§ï¼Œå»ºè®®ä¸è¦è®¾å¤ªå¤§ä»¥å…è§¦å‘ Rate Limit
    triple_generator = LLMGenerator(client, model_name=args.model, max_workers=8)

    # 4. é…ç½®æŠ½å–å‚æ•°
    # è¿™é‡Œæˆ‘ä»¬å°† window_size å’Œ window_overlap æ³¨å…¥åˆ° Config ä¸­
    kg_config = ProcessingConfig(
        model_path=args.model,
        data_directory=args.data_dir,
        filename_pattern=args.filename,
        output_directory=f"./generation_result/{args.model}", # ç»“æœè¾“å‡ºä½ç½®
        batch_size_triple=5,   # å¤šæ¨¡æ€ Payload å¾ˆå¤§ï¼ŒBatch Size å»ºè®®è°ƒå° (5-10)
        max_new_tokens=4096,
        record=True,           # è®°å½• Token æ¶ˆè€—
        # debug_mode= True,      # è°ƒè¯•æ¨¡å¼ï¼Œåªå¤„ç†å‰20ä¸ªæ ·æœ¬
        # --- å¤šæ¨¡æ€ç‰¹æœ‰å‚æ•° (ä¼šè¢« getattr è¯»å–) ---
        # window_size=10, 
        # window_overlap=2
    )
    # æ‰‹åŠ¨è¡¥ä¸ï¼šå› ä¸º ProcessingConfig æ˜¯ dataclassï¼Œå¯èƒ½ä¸æ”¯æŒç›´æ¥ä¼ æœªçŸ¥å‚æ•°
    # æˆ‘ä»¬æ‰‹åŠ¨ç»‘ä¸Šå»ï¼ŒMultimodalDataProcessor ä¼šç”¨ getattr è¯»å–
    kg_config.window_size = 10
    kg_config.window_overlap = 2

    # 5. å¯åŠ¨æŠ½å–
    print(f"ğŸš€ [Start] Extracting KG from {args.filename} using {args.model}...")
    start_time = time.time()

    extractor = MultimodalKGExtractor(model=triple_generator, config=kg_config)
    extractor.run_extraction()

    total_time = time.time() - start_time
    print(f"ğŸ‰ [Done] Total time: {total_time:.2f} seconds")


if __name__ == "__main__":
    # setting logger, print info in console
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[logging.StreamHandler()]
    )
    # filter httpx info
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logger.info("Starting Multimodal KG Extraction")

    main()